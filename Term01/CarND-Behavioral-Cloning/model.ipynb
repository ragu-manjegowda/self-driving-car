{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from scipy.misc import toimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pre-processing Images\n",
    "\n",
    "# Re-size images down to a quarter of original size, to speed up training\n",
    "def resize(img):\n",
    "    img = img.resize((80, 40), Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "#Cutting the image to the section, that holds the road information\n",
    "def cut_top_portion_of_images(image):\n",
    "    array_Image = np.array(image)\n",
    "    array_Cut = array_Image[15:]\n",
    "    return array_Cut\n",
    "\n",
    "#Converting the RGB Image to an HLS Image\n",
    "def convert_to_HLS(img):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    return hls\n",
    "\n",
    "#Normalizing the input Image\n",
    "def normalize(image_data):\n",
    "    max = 255. #np.max(img)\n",
    "    return (((image_data) / max) - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6242\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Reading the driving log to match stearing information to Images\n",
    "with open('./driving_log.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    driving_list = list(reader)\n",
    "    \n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "print(len(driving_list))\n",
    "#Preprocess all Images with cut/convert to HLS/Normalize\n",
    "for i, row in enumerate(driving_list):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    #if i == 1:\n",
    "    #print(row[0])\n",
    "    groups = row[0].split('/')\n",
    "    #print(groups)\n",
    "    #print('/'.join(groups[n:]))\n",
    "    image = Image.open(\"./IMG/\" + groups[-1])\n",
    "    #toimage(image).show()\n",
    "    image = resize(image)\n",
    "    #toimage(image).show()\n",
    "    image = cut_top_portion_of_images(image)\n",
    "    #toimage(image).show()\n",
    "    image = convert_to_HLS(image)\n",
    "    #toimage(image).show()\n",
    "    image = normalize(image)\n",
    "    #toimage(image).show()\n",
    "\n",
    "    X_train.append(image)\n",
    "    y_train.append(row[3])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "\n",
    "#shuffle and split Training Data into Train and Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequential Model\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "```\n",
    "The `keras.models.Sequential` class is a wrapper for the neural network model. Just like many of the class models in scikit-learn, it provides common functions like `fit()`, `evaluate()`, and `compile()`.  We'll cover these functions as we get to them.  Let's start looking at the layers of the model.\n",
    "\n",
    "## Keras Layer\n",
    "A Keras layer is just like a neural network layer.  It can be fully connected, max pool, activation, etc.  You can add a layer to the model using the model's `add()` function.  For example, a simple model would look like this:\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "\n",
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Layer - Add a flatten layer\n",
    "model.add(Flatten(input_shape=(32, 32, 3)))\n",
    "\n",
    "# 2nd Layer - Add a fully connected layer\n",
    "model.add(Dense(100))\n",
    "\n",
    "# 3rd Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# 4th Layer - Add a fully connected layer\n",
    "model.add(Dense(60))\n",
    "\n",
    "# 5th Layer - Add a ReLU activation layer\n",
    "model.add(Activation('relu'))\n",
    "```\n",
    "Keras will automatically infer the shape of all layers after the first layer.  This means you only have to set the input dimensions for the first layer.\n",
    "\n",
    "The first layer from above, `model.add(Flatten(input_shape=(32, 32, 3)))`, sets the input dimension to (32, 32, 3) and output dimension to (3072=32\\*32\\*3).  The second layer takes in the output of the first layer and sets the output dimenions to (100).  This chain of passing output to the next layer continues until the last layer, which is the output of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "1. Compile the network using adam optimizer and categorical_crossentropy loss function.\n",
    "2. Train the network for ten epochs and validate with 20% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4992 train samples\n",
      "1249 test samples\n",
      "(25, 80, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "nb_epoch = 15\n",
    "pool_size = (2, 2)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_val.astype('float32')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_val.shape[0], 'test samples')\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4992 samples, validate on 1249 samples\n",
      "Epoch 1/15\n",
      "29s - loss: 0.0929 - mean_squared_error: 0.0929 - val_loss: 0.0898 - val_mean_squared_error: 0.0898\n",
      "Epoch 2/15\n",
      "28s - loss: 0.0703 - mean_squared_error: 0.0703 - val_loss: 0.0777 - val_mean_squared_error: 0.0777\n",
      "Epoch 3/15\n",
      "28s - loss: 0.0662 - mean_squared_error: 0.0662 - val_loss: 0.0761 - val_mean_squared_error: 0.0761\n",
      "Epoch 4/15\n",
      "28s - loss: 0.0634 - mean_squared_error: 0.0634 - val_loss: 0.0671 - val_mean_squared_error: 0.0671\n",
      "Epoch 5/15\n",
      "28s - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0624 - val_mean_squared_error: 0.0624\n",
      "Epoch 6/15\n",
      "28s - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0669 - val_mean_squared_error: 0.0669\n",
      "Epoch 7/15\n",
      "28s - loss: 0.0592 - mean_squared_error: 0.0592 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
      "Epoch 8/15\n",
      "28s - loss: 0.0587 - mean_squared_error: 0.0587 - val_loss: 0.0582 - val_mean_squared_error: 0.0582\n",
      "Epoch 9/15\n",
      "28s - loss: 0.0613 - mean_squared_error: 0.0613 - val_loss: 0.0602 - val_mean_squared_error: 0.0602\n",
      "Epoch 10/15\n",
      "28s - loss: 0.0576 - mean_squared_error: 0.0576 - val_loss: 0.0541 - val_mean_squared_error: 0.0541\n",
      "Epoch 11/15\n",
      "28s - loss: 0.0561 - mean_squared_error: 0.0561 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "Epoch 12/15\n",
      "28s - loss: 0.0546 - mean_squared_error: 0.0546 - val_loss: 0.0549 - val_mean_squared_error: 0.0549\n",
      "Epoch 13/15\n",
      "28s - loss: 0.0531 - mean_squared_error: 0.0531 - val_loss: 0.0528 - val_mean_squared_error: 0.0528\n",
      "Epoch 14/15\n",
      "28s - loss: 0.0541 - mean_squared_error: 0.0541 - val_loss: 0.0530 - val_mean_squared_error: 0.0530\n",
      "Epoch 15/15\n",
      "28s - loss: 0.0515 - mean_squared_error: 0.0515 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNorma (None, 25, 80, 3)     12          batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 23, 78, 64)    1792        batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 23, 78, 64)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 23, 78, 64)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 21, 76, 32)    18464       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 21, 76, 32)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 19, 74, 16)    4624        activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 19, 74, 16)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 17, 72, 8)     1160        activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 17, 72, 8)     0           convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 8, 36, 8)      0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 2304)          0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 2304)          0           flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 128)           295040      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 128)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 64)            8256        dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 64)            0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 32)            2080        activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_7 (Activation)        (None, 32)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             33          activation_7[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 331,461\n",
      "Trainable params: 331,455\n",
      "Non-trainable params: 6\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(BatchNormalization(input_shape=input_shape))\n",
    "\n",
    "# Convolutional Layer 1 and Dropout\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(Convolution2D(8, 3, 3, border_mode='valid', subsample=(1,1)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "# Flatten and Dropout\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Fully Connected Layer 1 and Dropout\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# FC Layer 2\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# FC Layer 3\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Final FC Layer - just one output - steering angle\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compiling and training the model\n",
    "model.compile(metrics=['mean_squared_error'], optimizer='Nadam', loss='mean_squared_error')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, verbose=2, validation_data=(X_val, y_val))\n",
    "\n",
    "# Save model architecture and weights\n",
    "model_json = model.to_json()\n",
    "with open(\"./model.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "\n",
    "model.save_weights('./model.h5')\n",
    "\n",
    "# Show summary of model\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
